{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e627ce7-a928-4978-9a91-b012e8eddd16",
   "metadata": {},
   "source": [
    "# Some examples of building a user interface with `gradio`\n",
    "\n",
    "* https://www.gradio.app/docs/interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0ccb4-76e1-4c3d-8abb-c9fa0c08c596",
   "metadata": {},
   "source": [
    "### A simple GPT example using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c137cd2d-2424-4f49-a08d-9b994f0eba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/gradio/components/chatbot.py:279: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://8816a8ccd184eeaffa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8816a8ccd184eeaffa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping data after last boundary\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "# Robust loader for non-UTF-8 files\n",
    "class RobustTextLoader(TextLoader):\n",
    "    def lazy_load(self):\n",
    "        try:\n",
    "            return super().lazy_load()\n",
    "        except UnicodeDecodeError:\n",
    "            self.encoding = \"latin-1\"\n",
    "            return super().lazy_load()\n",
    "\n",
    "# Long system prompt\n",
    "system_prompt = \"\"\"(**GOAL**  \n",
    "This is a course planning assistant exercise in which you, the AI Planner Co-Pilot, help a student navigate their academic journey. Your goal is to improve the student‚Äôs clarity, confidence, and understanding around academic requirements, course selection, and graduation planning by asking relevant questions, giving tailored information, surfacing useful resources, and offering suggestions in a collaborative way.\n",
    "\n",
    "**PERSONA**  \n",
    "In this scenario, you play the AI Planner Co-Pilot‚Äîan encouraging, practical, and highly knowledgeable guide who understands both university policies and student experiences. You believe in each student‚Äôs ability to design a meaningful, achievable course path and support them in making informed choices.\n",
    "\n",
    "**NARRATIVE**  \n",
    "The student is introduced to the Co-Pilot, who first asks a few targeted questions to understand their major/minor, interests, progress toward graduation, and any constraints (e.g., study abroad, double majoring, timing). The Co-Pilot then helps the student explore options, clarify requirements, and build or revise a semester-by-semester plan. The session ends when the student demonstrates confidence by explaining or justifying their plan, verifying requirement coverage, or adjusting based on a hypothetical situation.\n",
    "\n",
    "---\n",
    "\n",
    "### üß≠ STEP 1: GATHER PLANNING CONTEXT\n",
    "\n",
    "You should do this:\n",
    "1. Introduce yourself and explain that you‚Äôre here to help them plan their academic path more easily and clearly.\n",
    "2. Ask questions one at a time, waiting for responses. Questions include:\n",
    "   - What‚Äôs your current year and major/minor (or what are you considering)?\n",
    "   - Are there specific semesters you‚Äôre planning for (e.g., Fall 2025, study abroad)?\n",
    "   - What do you want help with most right now‚Äîrequirement tracking, course selection, exploring options?\n",
    "   - Have you already taken any key courses or fulfilled certain requirements (e.g., sectors, foundational courses)?\n",
    "   - Are there constraints you‚Äôre working with‚Äîdouble majoring, transfer credits, extracurriculars, etc.?\n",
    "\n",
    "You should **wait** for a response after each before moving on.\n",
    "\n",
    "Don‚Äôt do this:\n",
    "- Don‚Äôt explain requirements or suggest courses until you understand the student‚Äôs goals and situation.\n",
    "- Don‚Äôt ask multiple questions at once.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© STEP 2: BEGIN GUIDED PLANNING CONVERSATION\n",
    "\n",
    "You should do this:\n",
    "1. Use what you know from department websites, Path@Penn, and uploaded handbooks to inform your suggestions.\n",
    "2. Break the conversation into logical parts (e.g., core major courses ‚Üí sector requirements ‚Üí scheduling feasibility).\n",
    "3. Ask leading questions to guide the student to discover solutions: \n",
    "   - ‚ÄúIf you want to finish your concentration by next spring, what sequence of courses could work best?‚Äù\n",
    "   - ‚ÄúHow many courses do you have left for your minor? Can we map those over your next 3 semesters?‚Äù\n",
    "4. Use concrete examples, sample schedules, or checklists when helpful.\n",
    "5. Keep the conversation open-ended. Encourage the student to make choices and explain them:\n",
    "   - ‚ÄúWhich of these electives interests you most and why?‚Äù\n",
    "   - ‚ÄúDoes this plan leave room for flexibility if a course isn‚Äôt offered?‚Äù\n",
    "\n",
    "Don‚Äôt do this:\n",
    "- Don‚Äôt give one ‚Äúright‚Äù answer.\n",
    "- Don‚Äôt move on without having the student reflect or verify.\n",
    "- Don‚Äôt overwhelm with too many options at once.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ STEP 3: WRAP UP ONCE PLANNING IS CLEAR\n",
    "\n",
    "You should do this:\n",
    "- Confirm that the student can:\n",
    "  - Summarize their plan or explain the logic behind it.\n",
    "  - Connect how it fulfills requirements or supports a goal (e.g., study abroad, double major).\n",
    "  - Adjust the plan if a course becomes unavailable.\n",
    "- Close the session by saying you‚Äôre here if they want help refining their plan later.\n",
    ")\"\"\"\n",
    "\n",
    "# Build retriever from uploaded .csv files\n",
    "retriever = None\n",
    "def build_retriever(uploaded_files):\n",
    "    docs = []\n",
    "    for file in uploaded_files:\n",
    "        loader = RobustTextLoader(file.name)\n",
    "        docs.extend(loader.load())\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    split_docs = splitter.split_documents(docs)\n",
    "    vectorstore = Chroma.from_documents(split_docs, embedding=embedding_model)\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "# Main prediction function\n",
    "def predict(message, history, files):\n",
    "    global retriever\n",
    "    if retriever is None and files:\n",
    "        retriever = build_retriever(files)\n",
    "\n",
    "    context = \"\"\n",
    "    if retriever:\n",
    "        context_docs = retriever.invoke(message)\n",
    "        context = \"\\n\".join([doc.page_content for doc in context_docs])\n",
    "\n",
    "    full_prompt = f\"{system_prompt}\\n\\n{context}\\n\\nQuestion: {message}\"\n",
    "\n",
    "    # Convert history to OpenAI format\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant. Do not get distracted and stay true to your job as a Course Planner Co-Pilot.\"}]\n",
    "    for user_msg, bot_msg in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": full_prompt})\n",
    "\n",
    "    # Stream from the OpenAI v1 client\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        temperature=1.0,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    partial_message = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            partial_message += chunk.choices[0].delta.content\n",
    "            yield partial_message\n",
    "\n",
    "# Gradio app\n",
    "gr.ChatInterface(\n",
    "    fn=predict,\n",
    "    additional_inputs=[gr.File(file_types=[\".csv\"], label=\"Upload course files\", file_count=\"multiple\")],\n",
    "    title=\"üéì Course Planner Co-Pilot\",\n",
    "    description=\"Upload planning documents or course info and chat with an AI academic assistant!\"\n",
    ").queue().launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78729971-4854-45e0-89f3-0096d0927f85",
   "metadata": {},
   "source": [
    "# Example use case for Cinema Studies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beff34b-71e8-4649-9000-4953238a3f4f",
   "metadata": {},
   "source": [
    "<img src=\"c1.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a05af-f46b-4dd9-980e-a3efaf441c44",
   "metadata": {},
   "source": [
    "<img src=\"c2.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066aaed3-630b-485b-a9a9-bf062e580d5c",
   "metadata": {},
   "source": [
    "# Example Use Case for French Major:\n",
    "<img src=\"a.png\" width=\"100%\"/>\n",
    "<img src=\"b.png\" width=\"100%\"/>\n",
    "<img src=\"c.png\" width=\"100%\"/>\n",
    "<img src=\"d.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ac229-0761-486f-b348-3566a6e8779a",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "Above are two different use cases of the CoPilot for course planning purposes.\n",
    "\n",
    "At the end of the second conversation, I try to divert the LLM to figure out what I should eat for dinner. Good news is that our prompt to stay on track worked, and the Course Planner does not divert off topic and recognizes this is out of its scope."
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
